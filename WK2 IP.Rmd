---
title: "Independent Projecrt"
output:
  pdf_document: default
  html_document: default
---

## Define the question
Identifing which individuals are most likely to click on our clients ads. 

## The metric for success
Successfully identifing the customers who are most likely to click on Ad

## The context
A Kenyan entrepreneur has created an online cryptography course and would want to advertise it on her blog. She currently targets audiences originating from various countries. In the past, she ran ads to advertise a related course on the same blog and collected data in the process. She would now like to employ your services as a Data Science Consultant to help her identify which individuals are most likely to click on her ads. 

## Experimental design taken
1. Define the question, the metric for success, the context, experimental design taken.

2. Read and explore the given dataset.

3. Define the appropriateness of the available data to answer the given question.

4. Find and deal with outliers, anomalies, and missing data within the dataset.

5. Perform univariate and bivariate analysis recording your observations.

6. From your insights provide a conclusion and recommendation.


## The appropriateness of the available data 
The data provided is sufficient to carry out our analysis.

## Loading the dataset.
```{r}
mydata = read.csv("http://bit.ly/IPAdvertisingData")
View(mydata)

```

## Checking the data
```{r}
# Checking for the first 6 rows
head(mydata)

```


```{r}
# Checking for the first 6 rows
tail(mydata)

```

```{r}
# Checking whether each column has an appropriate datatype

print("Daily.Time.Spent.on.Site data type")
class(mydata$Daily.Time.Spent.on.Site)

print("Age data type")
class(mydata$Age)

print("Area.Income data type")
class(mydata$Area.Income)

print("Daily.Internet.Usage data type")
class(mydata$Daily.Internet.Usage)

print("Ad.Topic.Line  data type")
class(mydata$Ad.Topic.Line )

print("City data type")
class(mydata$City)

print("Male data type")
class(mydata$Male)

print("Country data type")
class(mydata$Country)

print("Timestamp data type")
class(mydata$Timestamp)

print("Clicked.on.Ad data type")
class(mydata$Clicked.on.Ad)

```
All the columns are in the correct data type

```{r}
# Checking the unique values of each column

print("Daily.Time.Spent.on.Site unique values are:")
unique(mydata$Daily.Time.Spent.on.Site)

print("Age unique values are:")
unique(mydata$Age)

print("Area.Income unique values are:")
unique(mydata$Area.Income)

print("Daily.Internet.Usage unique values are:")
unique(mydata$Daily.Internet.Usage)

print("Ad.Topic.Line unique values are:")
unique(mydata$Ad.Topic.Line )

print("City unique values are:")
unique(mydata$City)

print("Male unique values are:")
unique(mydata$Male)

print("Country unique values are:")
unique(mydata$Country)

print("Clicked.on.Ad unique values are:")
unique(mydata$Clicked.on.Ad)

```
All the columns had the right data type but we will change the data type for male and Clicked.on.Ad from integer to factor because they are binary class therefore the categorical type will suit best.


```{r}
# Checking for the descriptive summary
summary(mydata)

```


## Tidying the Dataset
```{r}
# Checking for missing values
# to calculate the number of na values
print("the number of na values")
sum(is.na(mydata))

```
There are no missing values

### Changing the male and Clicked.on.Ad datatype
```{r}

# Changing to factor
mydata$Male = as.factor(mydata$Male)
mydata$Clicked.on.Ad = as.factor(mydata$Clicked.on.Ad)

# Checkingclass changed
class(mydata$Male)
class(mydata$Clicked.on.Ad)

# The class changed from integer to factor

print("Summary after")
summary(mydata)
```


### Duplicates
```{r}

mydata<- mydata[!duplicated(mydata), ]             # Remove duplicated rows
mydata                               # Print unique data

```
There are no duplicates

### Finding outliers

```{r}
# To check for outliers
boxplot(mydata)

# To have a clear view of the outliers we remove some columns
check <- mydata[, 3:9]

boxplot(check)

# We do a summary for all the columns with outliers
# For Area Income

IQR_income <- 65471 - 47032                  # Quantile Range
lowfen_income = 47032 - 1.5*IQR_income
lowfen_income

# For Daily.Internet.Usage

IQR_internet <- 218.8  - 138.8                  # Quantile Range
upfen_internet = 218.8  + 1.5*IQR_internet
upfen_internet

# The rest like  Ad.Topic.Line, City and Timestamp are in the class factor therefore the outliers in those do not affect the analysis


mydata2 = subset(mydata, Daily.Time.Spent.on.Site<=91.43  & Age<=61.00 & Area.Income<=19373.5 & Daily.Internet.Usage<=338.8)

boxplot(mydata2)
```
The outliers were removed.


## Exploratory Data Analysis

### Univariate Analysis
#### ***Mean***
```{r}
cat("The mean for Daily Time Spent on Site is",mean(mydata$Daily.Time.Spent.on.Site))
cat("\n")
cat("The mean for age is",mean(mydata$Age))
cat("\n")
cat("The mean for Area.Income is",mean(mydata$Area.Income))
cat("\n")
cat("The mean for daily Internet Usage is",mean(mydata$Daily.Internet.Usage))
cat("\n")

```


#### ***Median***
```{r}
# The simple printing method in R is to use print(). As its name indicates, this method prints its arguments on the R console. However, cat() does the same thing but is valid only for atomic types (logical, integer, real, complex, character) and names,


cat("The median for Daily Time Spent on Site is",median(mydata$Daily.Time.Spent.on.Site))
cat("\n")
cat("The median for age is",median(mydata$Age))
cat("\n")
cat("The median for Area.Income is",median(mydata$Area.Income))
cat("\n")
cat("The median for daily Internet Usage is",median(mydata$Daily.Internet.Usage))
cat("\n")

```

#### ***Mode***
```{r}
getmode <- function(v) {
   uniqv <- unique(v)
   uniqv[which.max(tabulate(match(v, uniqv)))]
}
```

```{r}
cat("The mode for income is",getmode(mydata$Area.Income))
cat("\n")
cat("The mode for daily time spent on site is",getmode(mydata$Daily.Time.Spent.on.Site))
cat("\n")
cat("The mode for gender is",getmode(mydata$Male))
cat("\n")
cat("The mode for age is",getmode(mydata$Age))
cat("\n")
cat("The mode for Daily Internet Usage",getmode(mydata$Daily.Internet.Usage))
```

#### ***Standard Deviation***
```{r}

cat("The standard deviation for Daily Time Spent on Site is",sd(mydata$Daily.Time.Spent.on.Site))
cat("\n")
cat("The standard deviation for age is",sd(mydata$Age))
cat("\n")
cat("The standard deviation for Area.Income is",sd(mydata$Area.Income))
cat("\n")
cat("The standard deviation for daily Internet Usage is",sd(mydata$Daily.Internet.Usage))
cat("\n")
```

#### ***Variance***
```{r}
cat("The variance for Daily Time Spent on Site is",var(mydata$Daily.Time.Spent.on.Site))
cat("\n")
cat("The variance for daily Internet Usage is",var(mydata$Daily.Internet.Usage))
cat("\n")
cat("The variance for age is",var(mydata$Age))
cat("\n")
cat("The variance for Area.Income is",var(mydata$Area.Income))

```

#### ***Quantile Range***
```{r}
cat("The Quantile for Daily Time Spent on Site is",quantile(mydata$Daily.Time.Spent.on.Site))
cat("\n")
cat("The Quantile for daily Internet Usage is",quantile(mydata$Daily.Internet.Usage))
cat("\n")
cat("The Quantile for age is",quantile(mydata$Age))
cat("\n")
cat("The Quantile for Area.Income is",quantile(mydata$Area.Income))
```

#### Histograms
```{r}
# Plotting the histograms
hist(mydata$Daily.Time.Spent.on.Site, main="Daily Time Spent on Site", xlab="time spent", ylab="frequency")

hist(mydata$Daily.Internet.Usage, main="Daily Internet Usage", xlab="internet spent", ylab="frequency")

hist(mydata$Age, main="Age", xlab="age", ylab="frequency")

hist(mydata$Area.Income, main="Area Income", xlab="income", ylab="frequency")
```

1. Time spent was highest between 75 to 80
2. Daily internet spent is highest between 120 and 140
3. The age that recorded the highest in between 30 to 35 years
4. The area income with the highest record is 60,000 to 65,000

### Bivariate Analysis
install.packages("ggplot2")
library(ggplot2)

```{r}
# Importing the packges needed
install.packages("ggplot2")
library(ggplot2)

ggplot(mydata, aes(x=Daily.Internet.Usage, fill=Clicked.on.Ad)) +
  geom_bar(position="dodge") + labs(title="Clicked Vs Internet Use")


ggplot(mydata, aes(x=Daily.Time.Spent.on.Site, fill=Clicked.on.Ad)) +
  geom_bar(position="dodge") + labs(title="Clicked Vs Time spent on site")

```

1. The more the internet useage incresed the customers did not click on Ad
2. The more they spent time on the site the more likely not to click On Ad


```{r}
ggplot(mydata, aes(x = Age, y = `Area.Income`, colour = Clicked.on.Ad)) +
  geom_point() + labs(title = 'Scatter plot for age vs daily time spent on site')
```
1. The age group above 40 are most likely to click on Ad
2. The clients earning 40,000 and above are most likely to not click on Ad.


## Create train/test set

```{r}
# We shuffle our dataset before splitting to ensure fair selection of the sample

shuffle_index <- sample(1:nrow(mydata))
head(shuffle_index)


# We generate a random list of index from 1 to 1000 (i.e. the maximum number of rows).
```


```{r}
# You will use this index to shuffle the mydata dataset

mydata <- mydata[shuffle_index, ]
head(mydata)

# We generate a random list of index from 1 to 1000 (i.e. the maximum number of rows).
```


arguments:
-data: Dataset used to train the model.
-size: Size of the split. By default, 0.8. Numerical value
-train: If set to `TRUE`, the function creates the train set, otherwise the test set. Default value sets to `TRUE`. Boolean value.You need to add a Boolean parameter because R does not allow to return two data frames simultaneously.


```{r}
# Creating Training and Test dataset
create_train_test <- function(data, size = 0.8, train = TRUE) {
  n_row = nrow(data)
  total_row = size * n_row
  train_sample = c(1: total_row)
  if (train == TRUE) {
    return (data[train_sample, ])
  } else {
    return (data[-train_sample, ])
  }
}


data_train <- create_train_test(mydata, 0.8, train = TRUE)
data_test <- create_train_test(mydata, 0.8, train = FALSE)

dim(data_train)
dim(data_test)

```



```{r}
# You use the function prop.table() combined with table() to verify if the randomization process is correct.

print("For Train:")
prop.table(table(data_train$Clicked.on.Ad))
cat("\n")
print("For Test:")
prop.table(table(data_test$Clicked.on.Ad))

```


## Implement the Solution - Modeling
### Decision Trees
```{r}
# Install rpart.plot
# install.packages("rpart.plot")

library(rpart)
library(rpart.plot)


fit <- rpart(formula = Clicked.on.Ad ~ Area.Income + Daily.Internet.Usage + Daily.Time.Spent.on.Site + Age, data = data_train, method = 'class')
rpart.plot(fit, extra = 106)


# if y is a factor then method = "class" is assumed
# extra=106 class model with a binary response
           
```

1) At the top, it is the overall probability of clicking on ad. It shows the proportion of customers that clicked on ad. 51 percent of customers clicked.

2) This node asks whether the daily internet usage is greater than or equal to 175. If no, then you go down to the root’s right child node. 47 percent are no with a clicking probability of 93 percent.

3) In the second node, you ask if the daily time spent on site is greater than or equal 74, if no, then 42 percent of the customers are on the no side and the chance of clicking on ad is 98 percent.

4) For the area income, if it is greater than or equal to 50,000, if no 2 percent of the customers would lie on the no side with a clicking probability of 94%

5) For age, if the age is less than 50, if no 1 percent of the customers have a clicking probability of 70 percent

What we are seeing is in line with the results that we got from our bivariate analysis.


### Make a prediction
```{r}
# We want to predict which customers are more likely to click on ad from the test set
predict_unseen <-predict(fit, data_test, type = 'class')


# Testing the passenger who didn’t make it and those who did.

table_mat <- table(data_test$Clicked.on.Ad, predict_unseen)
table_mat

```

The model correctly predicted 97 customers that didnt click on ad but classified 8 customers who clicked as they did not click. By analogy, the model misclassified 7 customers as those to have clicked while they did not click on ad.


### Measure performance

You can compute an accuracy measure for classification task with the confusion matrix, this means that you can compute the accuracy test from the confusion matrix:

```{r}
accuracy_Test <- sum(diag(table_mat)) / sum(table_mat)
print(paste('Accuracy for test', accuracy_Test))

```




```{r}
# Finding the accuracy of the train set

predict_unseen1 <-predict(fit, data_train, type = 'class')


# Testing the passenger who didn’t make it and those who did.

table_mat1 <- table(data_train$Clicked.on.Ad, predict_unseen1)
table_mat1

accuracy_Train <- sum(diag(table_mat1)) / sum(table_mat1)
print(paste('Accuracy for train', accuracy_Train))


```


## Challenge the Solution
### Tune the hyper-parameters

```{r}
# We will proceed as follow:

# 1. Construct function to return accuracy
# 2. Tune the maximum depth
# 3.Tune the minimum number of sample a node must have before it can split
# 4. Tune the minimum number of sample a leaf node must have


accuracy_tune <- function(fit) {
    predict_unseen <- predict(fit, data_test, type = 'class')
    table_mat <- table(data_test$Clicked.on.Ad, predict_unseen)
    accuracy_Test <- sum(diag(table_mat)) / sum(table_mat)
    accuracy_Test
}


```





```{r}
#  We tune the parameters and see if we can improve the model over the default value

control <- rpart.control(minsplit = 4,
    minbucket = round(5 / 3),
    maxdepth = 3,
    cp = 0)
tune_fit <- rpart(formula = Clicked.on.Ad ~ Area.Income + Daily.Internet.Usage + Daily.Time.Spent.on.Site + Age, data = data_train, method = 'class', control = control)

accuracy_tune(tune_fit)

```

The tuning did not increase the accuracy of our model , therefore we leave our model as is.



## Conclusion
The conclusions we can make are:

1. Time spent was highest between 75 to 80
2. Daily internet spent is highest between 120 and 140
3. The age that recorded the highest was in between 30 to 35 years
4. The area income with the highest record is 60,000 to 65,000
5. The more the internet useage incresed the customers did not click on Ad
6. The more the customer spent time on the site the more likely not to click On Ad
7. The age group above 40 are most likely to click on Ad
8. The clients earning 40,000 and above are most likely to not click on Ad.

Therefore the people most likely to click on Ad are:

1. The ones who log onto the site before up data
2. Customers who earn less than 40,000 are more likely to click on ad
3. The older customers ie 40 and above 
4. The less time they spend on the site the more likely they are to click on Ad.

## Recommendation
The Ads should target customers,

1. With a specific income range
2. Of an older audience that is 40 and above
3. Ads should come at the beginning to increase the likelihood of clicking

